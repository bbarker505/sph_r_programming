---
title: "Introduction to Tidymodels"
author: "Ted Laderas"
date: "12/7/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Before you get started

Please review the machine learning introduction before you start working with this notebook. It will acquaint you with the terminology you will need to understand to work with `tidymodels`.

# Glossary

-   *Machine Learning* - utilizing algorithms to discover and utilize patterns in a dataset
-   *Engine* - `tidymodels` speak for a machine learning package that has an algorithm - usually a specific package such as `ranger`
-   *Features* - machine learning speak for *variables* used in your model (usually a column) used to predict your outcome (also known as *predictors*)
-   *Training Set* - a set of data used for training your models
-   *Test Set* - a set of data used for testing your model 
    - *must* be a distinct subset from the training set.
-   *Unsupervised Learning* - A machine learning task for examining groupings/variability in a dataset. Examples include clustering, principle components analysis, TSNE.
-   *Supervised Learning* - A machine learning task for predicting the identity of a sample (usually a row) based on other data.

# Caveat

This is meant to only be an introduction to the machine learning workflow rather than a comprehensive overview. I highly recommend that you think about taking an online machine learning course to follow this up.

There is a neural network/deep learning course at OHSU, and Xubo Song's Machine Learning course in DMICE, as well as Melanie Mitchell's machine learning course at PSU.

# Learning Objectives

-   *Utilize* the `resample` package to produce test/train datasets
-   *Understand* how the `recipes` package makes preprocessing reproducible
-   *Apply* a recipe to a dataset to preprocess it
-   *Utilize* data reduction methods, such as PCA and UMAP for exploratory data analysis.
-   **Utilize** k-means clustering to understand our data

# What is `tidymodels`?

There are a lot of different packages and machine learning methods available for R. One big issue is that the output of all of these models is not standardized - for example, if you wanted a p-value from a model, you'd look in different places for the results.

The `tidymodels` workflow is designed to map to common tasks you use for machine learning.
                                                                                                                                                                                                                          


## Step 1: Explore the Data First

We need to do a little bit of tidying on the `penguins` data before we can use it. The first thing we need to do is select the numeric measurements, and then subset the species to be only two species instead of three.

```{r}
library(palmerpenguins)
library(tidymodels)
library(rsample)
library(tidyverse)
set.seed(101050)

data("penguins")

penguins_matrix <- penguins %>% 
  select(species, c(contains("mm"), contains("_g"))) %>%
  filter(species %in% c("Chinstrap", "Adelie")) %>%
  filter(complete.cases(.)) %>%
  mutate(species = forcats::fct_drop(species))
```

```{r}
skimr::skim(penguins_matrix)
```

# Step 2: {rsample} - split the data up

Build test/train set. `strata` argument ensures that there is equivalent sampling across both test and train set.

```{r}
penguins_split <- initial_split(penguins_matrix, prop = 0.7, strata = species)

penguins_train <- training(penguins_split)
penguins_test <- rsample::testing(penguins_split)

dim(penguins_train)
```

# Step 3: {recipes} - process the data for use by our models

<https://www.tidymodels.org/start/recipes/>

-   Specifying Features, outcomes, and id columns with model formula
-   Convert factors to dummy variables
-   Normalizing Numeric Data
-   Exploring Data with Principal Components/UMAP

### Starting a recipe with `recipe()`

All preprocessing begins with the `recipe()` function:

    my_recipe <- recipe(species ~ . , data = penguin_train)

You can see that we provided an argument `data` to specify that our data should come from the `penguin_train` split from our data.




## How does recipes know what column is what?

There are three main column types in {recipes}:

-   *Outcomes* (what we want to predict)
-   *Features* (the columns we use to build our model)
-   *Identifiers* (columns not used in analysis, but are useful as unique identifiers, such as sample ids)

We can specify the outcomes and features in `recipe()` using a formula:

    species ~ . 

In our case, our outcome is `species` (because it is on the left of the `~`), and we use a `.` to denote that every other column is a potential feature, or predictor.

What if we had an id column in the data, such as `penguin_name`? We can use `update_role()` to tell `recipes` they're an id.

So, if we had `penguin_name` as an ID column in our data set, we'd do this at the beginning of our recipe:

    my_recipe <- recipe(species ~ . , data = penguin_train) %>%
         update_role(penguin_name, role = "ID")



## A recipe consists of `step_`s

Now we have our basic recipe built, it's time to add processing for the columns. These processing steps all begin with `step_` such as:

-   `step_normalize()` - scale all predictors to have a mean of 0 and standard deviation (SD) of 1 (done on `all_numeric()`)
-   `step_dummy()` - transform `factor` variables into dummy variables (usually do this on `all_nominal()` varia2wws2bles)
-   `step_arrange()` - sort data using `arrange()`

How does each step know what columns to process? We need to provide the column names as an argument. For example, if we wanted to just normalize the `bill_length_mm` and `bill_depth_mm` columns:

    my_recipe <- recipe(species ~ . , data = penguin_train) %>%
       step_normalize(bill_length_mm, bill_depth_mm)


## What is the difference between `{recipes}` and `{dplyr}`?

Most everything you can do in `{recipes}` can be done in `dplyr`. 

However, most of the operations in `{recipes}` are dedicating to processing data so you can input into a machine learning algorithm.




## Some handy selectors: `all_predictors()`

Using column names

Some steps you may want to run on all the predictors in the dataset, so you instead of the column names, you can use *selectors* instead.

If we wanted to `step_normalize` all the predictors, we can use `all_predictors()` instead of the column names:

    my_recipe <- recipe(species ~ . , data = penguin_train) %>%
       step_normalize(all_predictors())



There are some built in `all_`\* functions:

-   `all_numeric()` - apply step to all numeric variables in the dataset
-   `all_nominal()` - apply step to all categorical variables

In fact, if you know tidy select helpers, you can use these as well.


## Step Normalize


```{r}
normalized_recipe <- recipe(species ~., data = penguins_train) %>%
  step_normalize(all_numeric()) 

norm_prep <- prep(normalized_recipe)

norm_prep
```

```{r}
prepped_data <- juice(norm_prep)

prepped_data
```



```{r}
skimr::skim(prepped_data)
```

There is another step called `step_dummy()` that will transform categorical variables into dummy variables.

```{r}
normalized_recipe <- recipe(species ~., data = penguins_train) %>%
  step_normalize(all_numeric()) %>%
  step_dummy(all_nominal())

norm_prep <- prep(normalized_recipe)

juice(norm_prep)
```



## Step 3a Building a Recipe: Principal Components Analysis

Let's build a recipe that helps us explore the data.

We might want to start understanding how difficult it is to actually predict the species.

One technique we can use is `Principal Components Analysis` (PCA). PCA 

```{r}
pca_rec <- recipe(species ~., data = penguins_train) %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors())

pca_prep <- prep(pca_rec)
pca_prep
```


If you want to see the data that has been processed by `recipes` you need to run the `juice` command to produce the transformed data.

In this case, we want to see the principle components.

```{r}
pca_data <- juice(pca_prep)

pca_data
```

```{r}
tidied_pca <- pca_data %>%
  pivot_longer(-species, names_to="component", )

```

```{r}
pca_data %>%
  ggplot(aes(PC1, PC2)) +
  geom_point(aes(color = species), alpha = 0.7, size = 2) +
  labs(color = NULL)
```

Plot `PC1` versuse `PC3`:

```{r}
juice(pca_prep) %>%
  ggplot(aes(PC1, PC3)) +
  geom_point(aes(color = species), alpha = 0.7, size = 2) +
  labs(color = NULL)
```

### PCA: Contributions from each variable

Now we have our `tidied_pca` version of the data, let's take a look at the linear combinations:

```{r}
tidied_pca <- tidy(pca_prep, 2)

tidied_pca %>%
  filter(component %in% paste0("PC", 1:4)) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(value, terms, fill = terms)) +
  geom_col(show.legend = FALSE) +
  theme(axis.text.x =  element_text(angle = 45)) +
  facet_wrap(~component, nrow = 1) +
  labs(y = NULL)
```

This is a more informative plot that gives us an idea of the magnitude of the contributions to each prinicipal component.

```{r}
library(tidytext)

tidied_pca %>%
  filter(component %in% paste0("PC", 1:4)) %>%
  group_by(component) %>%
  ungroup() %>%
  mutate(terms = tidytext::reorder_within(terms, abs(value), component)) %>%
  ggplot(aes(abs(value), terms, fill = value > 0)) +
  geom_col() +
  facet_wrap(~component, scales = "free_y") +
  scale_y_reordered() +
  labs(
    x = "Absolute value of contribution",
    y = NULL, fill = "Positive?"
  )

```



## Clustering

https://www.tidymodels.org/learn/statistics/k-means/

We may want to ask the question of whether there are *natural* groupings in the data. We can do this with a *clustering* algorithm.

```{r}
knitr::include_graphics("image/kmeans.gif")
````

The only argument we supply to k-means is the number of clusters.

```{r}
penguins_numeric <- penguins_train %>%
  select(-species)

kmeans_model <- kmeans(penguins_numeric, centers = 2) 
```


## Comparing our Clusters to the Species Labels

We can add the cluster assignments using our `augment()` function, which will take our original `penguins_train` data.frame and add cluster assignments.

```{r}
clusters <- augment(kmeans_model, penguins_train)

clusters %>% 
  select(species, .cluster)
```

We can try a cross tab of our true `species` versus cluster assignments using `janitor::tabyl()`:

```{r}
clusters %>%
  janitor::tabyl(species, .cluster)
```



## Logistic Regression


Let's fit a logistic regression model to our data.

A **logistic regression** attempts to predict a binary variable (in our case: the species of penguin)

```{r}

penguins_train2 <- penguins_train %>%
  mutate(is_adelie = case_when(species == "Adelie" ~ 1,
                               species == "Chinstrap" ~ 0
                              )) %>%
  select(-species)

penguin_logit <- glm(species ~ bill_depth_mm + flipper_length_mm + body_mass_g, family = "binomial", data = penguins_train, maxit=100)

tidy(penguin_logit)
```


In a logistic regression, one of the outputs is a *predicted probability* - in our case, what is the probability that a penguin is going to be `Adelie`.

```{r}
penguin_augmented <- augment(penguin_logit, newdata = penguins_test, type.predict = "response")

penguin_augmented <- penguin_augmented %>%
  mutate(species = penguins_test$species)
```

Let's plot the predicted probability for each patient.

```{r}
ggplot(penguin_augmented) + aes(x=.fitted, fill=species) + 
  geom_histogram() + ggtitle("Predicted probability for each patient")
```

Separating out `Adelie` versus `Chinstrap` penguins is relatively easy using this dataset. We'll see this is the case when we run a *machine learning* algorithm next time.


## Your Turn

Given the above probability distribution plot, pick a probability threshold for the model that will separate out `Adelie` versus `Gentoo` penguins.

Make a crosstab of `species` versus `species_prediction`.

```{r}
cutoff <- 0.4

penguin_predictions <- 
  penguin_augmented %>% 
  mutate(species_prediction = case_when(.fitted > cutoff ~ "Chinstrap",
                                        TRUE ~ "Adelie")) %>%
  mutate(species_prediction = factor(species_prediction))

penguin_predictions %>%
  janitor::tabyl(species, species_prediction)
```

Once we have our predictions using `augment`

```{r}
library(yardstick)
conf_mat(penguin_predictions, truth = species, estimate = species_prediction)
bal_accuracy(penguin_predictions, truth = species, estimate=species_prediction)
sensitivity(penguin_predictions, truth = species, estimate = species_prediction)
specificity(penguin_predictions, truth = species, estimate = species_prediction)
```


Part of your assignment will be to run a logistic regression on `Adelie` versus `Chinstrap` penguins. 


# Running multiple formulas on a dataset (optional)

We can run multiple models by first specifying them as a `character` vector. We can then use `as.formula` to transform it into a formula: 

```{r}
penguin_formulas <- data.frame(
  formula = c("is_adelie ~ bill_depth_mm",
              "is_adelie ~ bill_length_mm + bill_depth_mm",
              "is_adelie ~ body_mass_g + bill_length_mm")
)

penguin_formulas
```

Here we're using `as.formula` to transform the `character` into a `formula`:

```{r}
run_model <- function(x){
  lm(formula = as.formula(x), data=penguins_train2)
}

multiple_models <- penguin_formulas %>%
  mutate(model = map(formula, run_model)) %>%
  mutate(tidy_output = map(model, broom::tidy)) %>%
  mutate(glanced_output = map(model, broom::glance))

multiple_models
```


```{r}
multiple_models %>%
  unnest(glanced_output)
```


```{r}
multiple_models %>%
  unnest(tidy_output)

```

I will note that variable selection is much easier to do in machine learning, and there is a more principled framework for selecting appropriate predictors.


## Trying different values of k (optional)

One question you might have is: how to pick k for the kmeans algorithm?

```{r}
kclusts <- 
  tibble(k = 1:5) %>%
  mutate(
    kclust = map(k, ~kmeans(penguins_numeric, .x)),
    tidied = map(kclust, tidy),
    glanced = map(kclust, glance),
    augmented = map(kclust, augment, penguins_numeric)
  )

kclusts
```


```{r}
assignments <- 
  kclusts %>% 
  unnest(cols = c(augmented))

clustering_information <- 
  kclusts %>%
  unnest(cols = c(glanced))
```

The output of `broom::glance()` contains metrics about the clustering, including the total within group sum of squares. As k increases, you can see this number go down.

```{r}
ggplot(clustering_information) +
  aes(x=k, y=tot.withinss) +
  geom_line()

```


```{r}
clusters
```

```{r}
clusterings
```

```{r}
  ggplot(assignments, aes(x = bill_depth_mm, y = body_mass_g)) +
  geom_point(aes(color = .cluster), alpha = 0.8) + 
  facet_wrap(~ k)
```

```{r}
assignments %>%
  janitor::tabyl(species)
```


### Running UMAP as a recipe (Optional)

Another method for summarizing numeric data is UMAP.

```{r}
library(embed)

umap_rec <- recipe(species ~., data = penguins_train) %>%
  step_normalize(all_predictors()) %>%
  step_umap(all_predictors())

umap_prep <- prep(umap_rec)

umap_prep

```

```{r}
umap_pca <- tidy(umap_prep, 2)

juice(umap_prep)
```

```{r}
juice(umap_prep) %>%
  ggplot(aes(umap_1, umap_2)) +
  geom_point(aes(color = species), alpha = 0.7, size = 2) +
  labs(color = NULL)
```



## Acknowledgements

Portions of this tutorial are adapted from

https://juliasilge.com/blog/cocktail-recipes-umap/
https://www.tidymodels.org/learn/statistics/k-means/
https://allisonhorst.github.io/palmerpenguins/articles/articles/pca.html
