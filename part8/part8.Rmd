---
title: "Introduction to Tidymodels"
author: "Ted Laderas"
date: "12/7/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Before you get started

Please review the machine learning introduction before you start working with this notebook. It will acquaint you with the terminology you will need to understand to work with `tidymodels`.

# Glossary

- Machine Learning - utilizing algorithms to discover and utilize patterns in a dataset
- Unsupervised Learning - A machine learning task for examining groupings/variability in a dataset
- Supervised Learning - A machine learning task for predicting the identity of a sample (usually a row)
- Engine - tidymodels speak for a machine learning algorithm, such as `lm()` or decision trees - usually a specific package such as [...]
- Features - machine learning speak for *variables* used in your model (usually a column)
- Training Set
- Test Set



# Caveat

This is meant to only be an introduction to the machine learning workflow rather than a comprehensive overview. I highly recommend that you think about taking an online machine learning course to follow this up. 

There is a neural network/deep learning course at OHSU, and 

# Learning Objectives

- *Utilize* the `resample` package to produce test/train datasets
- *Understand* how the `recipes` package makes preprocessing reproducible
- *Utilize* data reduction methods for analysis.
- *Run* and *interpret* three different machine learning methods and compare them


## What is `tidymodels`?

There are a lot of different packages and machine learning methods available for R. One big issue is that the output of all of these models is not standardized - for example, if you wanted a p-value from a model, you'd look in different places for the results. 

The `tidymodels` workflow is designed to map to common tasks you use for machine learning. 

## The different parts of `tidymodels`

The different sections of `tidymodels` are designed to be useful in a `tidy` workflow and roughly map to the different steps and requirements of a machine learning workflow.


```{r}
library(palmerpenguins)
library(tidymodels)
library(rsample)
library(tidyverse)

data("penguins")

penguins_matrix <- penguins %>% 
  select(species, c(contains("mm"), contains("_g"))) %>%
  filter(species %in% c("Chinstrap", "Adelie")) %>%
  filter(complete.cases(.)) %>%
  mutate(species = forcats::fct_drop(species))

penguins_split <- initial_split(penguins_matrix, prop = 0.85, strata = species)

penguins_train <- training(penguins_split)

dim(penguins_train)

pca_rec <- recipe(species ~., data = penguins_train) %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors())

pca_prep <- prep(pca_rec)

pca_prep

tidied_pca <- tidy(pca_prep, 2)


tidied_pca %>%
  filter(component %in% paste0("PC", 1:4)) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(value, terms, fill = terms)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~component, nrow = 1) +
  labs(y = NULL)
```
```{r}
juice(pca_prep)
```

```{r}
juice(pca_prep) %>%
  ggplot(aes(PC1, PC2)) +
  geom_point(aes(color = species), alpha = 0.7, size = 2) +
  labs(color = NULL)
```


Plot `PC1` versuse `PC3`

```{r}
juice(pca_prep) %>%
  ggplot(aes(PC1, PC3)) +
  geom_point(aes(color = species), alpha = 0.7, size = 2) +
  labs(color = NULL)
```
```{r}
library(embed)

umap_rec <- recipe(species ~., data = penguins_train) %>%
  step_normalize(all_predictors()) %>%
  step_umap(all_predictors())

umap_prep <- prep(umap_rec)

umap_prep

umap_pca <- tidy(umap_prep, 2)

juice(umap_prep)

juice(umap_prep) %>%
  ggplot(aes(umap_1, umap_2)) +
  geom_point(aes(color = species), alpha = 0.7, size = 2) +
  labs(color = NULL)

```

## Setup a recipe for our ML model


```{r}

classification_rec <- recipe(species ~., data = penguins_train) %>%
  step_normalize(all_predictors())

classification_rec

class_prep <- prep(classification_rec)

juice(class_prep)

skimr::skim(juice(class_prep))
```

```{r}
library(tune)

rf_model <- 
  # specify that the model is a random forest
  rand_forest() %>%
  # specify that the `mtry` parameter needs to be tuned
  set_args(mtry = tune()) %>%
  # select the engine/package that underlies the model
  set_engine("ranger", importance = "impurity") %>%
  # choose either the continuous regression or binary classification mode
  set_mode("classification") 

library(workflows)

rf_workflow <- workflow() %>%
  # add the recipe
  add_recipe(classification_rec) %>%
  # add the model
  add_model(rf_model)
```


```{r}
penguins_cv <- rsample::vfold_cv(penguins_train)

rf_grid <- expand.grid(mtry = c(3, 4, 5))
# extract results
rf_tune_results <- rf_workflow %>%
  tune_grid(resamples = penguins_cv, #CV object
            grid = rf_grid, # grid of values to try
            metrics = metric_set(accuracy, roc_auc) # metrics we care about
            )

```

```{r}
rf_tune_results %>%
  collect_metrics()
```

```{r}
param_final <- rf_tune_results %>%
  select_best(metric = "accuracy")
param_final

```

```{r}
rf_workflow <- rf_workflow %>%
  finalize_workflow(param_final)
```


```{r}
rf_fit <- rf_workflow %>%
  # fit on the training set and evaluate on test set
  last_fit(penguins_split)

test_performance <- rf_fit %>% collect_metrics()
test_performance
```

```{r}
test_predictions <- rf_fit %>% collect_predictions()
test_predictions

test_predictions %>% 
  conf_mat(truth = species, estimate = .pred_class)

test_predictions %>%
  ggplot() +
  geom_density(aes(x = .pred_Adelie, fill = species), 
               alpha = 0.5)
```

## Let's run through a basic tidymodels workflow

These are the packages 


- {resample} - use these functions to specify a test/training set
- {recipes} - use these functions to normalize variables
- {parsnip} - use these functions to specify and train your model
- {yardstick} - use these functions to evaluate your model


More advanced packages:

- {tune} - 
- {stacks}
- {workflows}


## Explore the Data First

```{r}
skimr::skim(penguins)

```


## Resample

Subset to Adelie/Gentoo

```{r}
two_species <- penguins %>%
  filter(species %in% c("Gentoo", "Adelie"))
```


Build test/train set

```{r}


```


## Recipes

Prinicipal Components/UMAP
Normalizing Data
Specifying Features

## Parsnip

Specifying model type
Training model type

## Yardstick

Evaluating Accuracy
Comparing different methods


## Assignment

Pick two ML methods to compare for this task


## Acknowledgements

Adapted from http://www.rebeccabarter.com/blog/2020-03-25_machine_learning/
http://www.rebeccabarter.com/blog/2019-06-06_pre_processing/
https://juliasilge.com/blog/cocktail-recipes-umap/
