---
title: 'Part 10: Machine Learning: Classification'
author: "You"
date: "3/1/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidymodels)
library(tidyverse)
library(rsample)
library(tidyverse)
library(palmerpenguins)
set.seed(101050)

data("penguins")

penguins_matrix <- penguins %>% 
  select(species, c(contains("mm"), contains("_g"))) %>%
  filter(species %in% c("Chinstrap", "Adelie")) %>%
  filter(complete.cases(.)) %>%
  mutate(species = forcats::fct_drop(species))

```

# Learning Objectives

- **Discuss** the difference between statistical modeling and machine learning
- **Compile** a recipe to process our data
- **Specify** and **fit** a machine learning algorithm to our data using `{parsnip}`
- **Integrate** our recipe and our algorithm to make a *workflow*. 
- **Run** multiple workflows
- **Assess** our predictive model using `{yardstick}`.

# Glossary

-   *Machine Learning* - utilizing algorithms to discover and utilize patterns in a dataset
-   *Engine* - `tidymodels` speak for a machine learning package that has an algorithm - usually a specific package such as `ranger`
-   *Features* - machine learning speak for *variables* used in your model (usually a column) used to predict your outcome (also known as *predictors*)
-   *Training Set* - a set of data used for training your models
-   *Test Set* - a set of data used for testing your model - *must* be a distinct subset from the training set.
-   *Unsupervised Learning* - A machine learning task for examining groupings/variability in a dataset. Examples include clustering, principle components analysis, TSNE.
-   *Supervised Learning* - A machine learning task for predicting the identity of a sample (usually a row) based on other data.



# Statistical Modeling versus Machine Learning

https://towardsdatascience.com/the-actual-difference-between-statistics-and-machine-learning-64b49f07ea3

> there are lots of statistical models that can make predictions, but predictive accuracy is not their strength.

> Likewise, machine learning models provide various degrees of interpretability, from the highly interpretable lasso regression to impenetrable neural networks, but they generally sacrifice interpretability for predictive power.

> For many cases, especially in research (such as the sensor example below), the point of our model is to characterize the relationship between the data and our outcome variable, not to make predictions about future data. 

> The purpose of (supervised) machine learning is obtaining a model that can make repeatable predictions. 


>  The assessment of the machine learning algorithm uses a test set to validate its accuracy. Whereas, for a statistical model, analysis of the regression parameters via confidence intervals, significance tests, and other tests can be used to assess the modelâ€™s legitimacy. 



# Resources for understanding preprocessing of data in Machine Learning

[Max Kuhn's Feature Engineering](http://www.feat.engineering/) book is one of the best sources I know if you want to understand why preprocessing features is so important for machine learning.




# Step 1: {rsample} - split the data up

Build test/train set. 

```{r}
penguins_split <- initial_split(penguins_matrix, prop = 0.7, strata = species)

penguins_train <- training(penguins_split)
penguins_test <- rsample::testing(penguins_split)

dim(penguins_train)
```


## Step 2: Setup a `recipe` for our ML model

Ok, the PCA gave us an idea of how hard it is to separate the two different penguin species.

We can set up a recipe for preprocessing the numeric data in our model. We use `step_normalize()` to standardize the ranges of each variable.

Again, we need to provide a formula at this step because it helps `tidymodels` identify what the outcome is, what the features are, and what shouldn't be included.

```{r}
classification_rec <- recipe(species ~., data = penguins_train) %>%
  step_normalize(all_predictors())

classification_rec
```

Let's take a look at the transformed data.

```{r}
class_prep <- prep(classification_rec)

class_data_train <- bake(class_prep, new_data = NULL)

skimr::skim(class_data_train)
```


## Step 3 {parsnip} - specify the model

Once you have the preprocessed data that is split properly, you can use it as an input to {parsnip}. But first we need a model!

A model specifies the type of algorithm we want to use, and what *engine* we want to use to calculate it, and based on how it is used, the *mode* (usually classification or regression) we want to use it in.

-   Specifying model type/engine
-   (Learning optimum parameters for a model {tune/rsample})
-   Fitting the model to training data

## What models exist?

Nearly all of the popular machine learning methods work within the `tidymodels` framework.

Check here for a list: <https://www.tidymodels.org/find/parsnip/>

## Specifying a Logistic Regression Model

This might seem like extra typing, but we'll see we can run the same formula using different algorithms.

```{r}
lr_model <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

lr_fit <- fit(object= lr_model, 
               formula = species ~ bill_length_mm,
               data = class_data_train)

```

If we use `pluck()` we can see that what comes out of `fit()` has a `glm.fit` class:

```{r}
lr_fit %>% pluck("fit") 
```

# Step 4 - Testing our predictions using `yardstick`

Now we can visualize the probabilities that are calculated by our logistic regression model.

```{r}
class_data_test <- bake(class_prep, new_data = penguins_test)

lr_probabilities <- lr_fit %>%
  predict(new_data = class_data_test, type="prob") %>%
  bind_cols(penguins_test)

lr_probabilities %>%
  ggplot() + aes(x=.pred_Adelie, fill=species) +
  geom_histogram()
```


## Predicting the type of penguin using predict

```{r}
lr_predictions <- lr_fit %>%  
  predict(new_data = class_data_test, type="class") %>%
  bind_cols(penguins_test) %>%
  rename(truth = species, estimate=.pred_class)

lr_predictions %>%
  yardstick::conf_mat(truth = truth, estimate=estimate)

lr_predictions 

```


```{r}
lr_predictions %>%
  yardstick::accuracy(truth = truth, estimate= estimate)
```


```{r}
lr_predictions %>%
  yardstick::bal_accuracy(truth = truth, estimate= estimate)
```


```{r}
lr_predictions %>%
  yardstick::sensitivity(truth = truth, estimate= estimate, event_level = "first")
```

```{r}
lr_predictions %>%
  yardstick::specificity(truth = truth, estimate= estimate, event_level = "first")
```


## The Full Logistic Regression Workflow

This is the whole workflow summarized into an entire code block.

```{r}
#Part 1: split our data into test and train sets
penguins_split <- initial_split(penguins_matrix, prop = 0.7, strata = species)

penguins_train <- training(penguins_split)
penguins_test <- rsample::testing(penguins_split)

#Part 2: setup the recipe using the training data
classification_rec <- recipe(species ~., data = penguins_train) %>%
  step_normalize(all_predictors()) 

#apply the recipe to the training data
class_prep <- prep(classification_rec)
class_data_train <- bake(class_prep, new_data = NULL)

#Part 3: specify the model 
lr_model <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

#fit ("train") the model
lr_fit <- fit(object= lr_model, 
               formula = species ~ .,
               data = class_data_train)

#Part 4: apply our recipe to the test set
class_data_test <- bake(class_prep, new_data = penguins_test)

#use our fitted model to predict species
lr_predictions <- lr_fit %>%  
  predict(new_data = class_data_test, type="class") %>%
  #bind our predictions back to the original data
  bind_cols(penguins_test) %>%
  rename(truth = species, estimate=.pred_class)

#look at our confusion matrix
lr_predictions %>%
  yardstick::conf_mat(truth = truth, estimate= estimate)

#look at our accuracy of our predicted classes
lr_predictions %>%
  yardstick::bal_accuracy(truth = truth, estimate= estimate)
```



### Using a Machine Learning algorithm - K Nearest Neighbor

Now we've learned about models and building fits, we can see we can swap out the algorithm pretty easily and run the same formula. 

A really robust model we can use to predict our `species` is [`K-Nearest Neighbor`](). For a brand new point, we look at closely correlated points ("neighbors") and we use the identity of each of these points as a vote for the identity of our new point.

Why should `neighbors` be an odd value?

```{r} 
knn_model <- nearest_neighbor(neighbors = 3) %>% 
  set_engine("kknn") %>% 
  set_mode("classification")
```

```{r }
knn_fit <- fit(object= knn_model, 
               formula = species ~ .,
               data = class_data_train)

knn_fit
```

```{r}
knn_predictions <- knn_fit %>%
  predict(new_data = class_data_test) %>%
  bind_cols(penguins_test) %>%
  rename(truth = species, estimate=.pred_class)

knn_predictions %>%
  janitor::tabyl(truth, estimate)

knn_predictions %>%
  yardstick::accuracy(truth, estimate)
```

## Your Turn

Compare the `sensitivity` and `specificity` of `knn_predictions` to our `lr_predictions` (remember to set event_level = "first"). Did we do better or worse than logistic regression? In which metric?

```{r}
knn_predictions %>%
  yardstick::-------------

knn_predictions %>%
  yardstick::----------
  
```


## Classification and Decision Trees (CART)

Apply a decision tree using the following model. Compare how you did with KNN on the test data using `last_fit()`:


```{r}
tree_model <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")

tree_fit <- fit(tree_model, 
                formula = species ~ . ,
                data=class_data_train)

penguin_predictions <- tree_fit %>%
  predict(new_data=class_data_test) %>%
  bind_cols(penguins_test) %>%
  rename(truth=species, estimate=.pred_class)
  
penguin_predictions %>% 
  yardstick::accuracy(truth, estimate)
```


```{r warning=FALSE}
rpart_object <- tree_fit %>% pluck("fit")
rpart.plot::rpart.plot(rpart_object)
```






## Acknowledgements

Adapted from

-   <http://www.rebeccabarter.com/blog/2020-03-25_machine_learning/>
-   <http://www.rebeccabarter.com/blog/2019-06-06_pre_processing/>
-   <https://juliasilge.com/blog/cocktail-recipes-umap/>
-   <https://bcullen.rbind.io/post/2020-06-02-tidymodels-decision-tree-learning-in-r/>
-   [Feature Engineering](http://www.feat.engineering/)
